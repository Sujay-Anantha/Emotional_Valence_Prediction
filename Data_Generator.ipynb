{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hWmCSfmPFjjV"
   },
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from google.colab import drive\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYHhS6iuQxUd",
    "outputId": "7f548401-b5e7-4935-daa0-a47729ffe5d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shdy2AKGRtVk"
   },
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "wikiart_dir = '/content/drive/MyDrive/DeepLearningProject/wikiart'\n",
    "artemis_data_file = '/content/drive/MyDrive/DeepLearningProject/ProcessedData/artemis_preprocessed.csv'\n",
    "\n",
    "# Load the ArtEmis data\n",
    "artemis_data = pd.read_csv(artemis_data_file)\n",
    "\n",
    "# Define emotion label encoder\n",
    "le = LabelEncoder()\n",
    "le.fit(artemis_data['emotion'])\n",
    "\n",
    "# Define image size\n",
    "img_size = (224, 224)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_image(file_path):\n",
    "    # Read the image from the file_path using TensorFlow's io.read_file and image.decode_image functions\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.image.decode_image(image)\n",
    "\n",
    "    # Resize the image to the desired size (img_size) using TensorFlow's image.resize function\n",
    "    image = tf.image.resize(image, img_size)\n",
    "\n",
    "    # Convert the color space of the image from BGR (default in OpenCV) to RGB using TensorFlow's image.rgb_to_grayscale function\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "\n",
    "    # Normalize the pixel values of the image by converting the data type to float32 and dividing by 255.0\n",
    "    # This brings the pixel values to the range [0, 1] which is commonly used in deep learning models\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # Return the preprocessed image\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o62Owt1_0GAL"
   },
   "source": [
    "The code starts by defining the paths to the data directories and files, specifically the directory containing the WikiArt images (wikiart_dir) and the file path to the preprocessed ArtEmis data (artemis_data_file). The ArtEmis data is loaded into a pandas DataFrame using the read_csv function. The data is read from the CSV file specified by artemis_data_file.\n",
    "\n",
    "The code defines a label encoder (le) to encode the emotion labels present in the ArtEmis data. The encoder is fit on the 'emotion' column of the ArtEmis DataFrame using the fit method. The image size is defined as (224, 224), indicating the desired dimensions for the images after resizing. TensorFlow library is imported as tf.\n",
    "\n",
    "The code defines a function called load_image that takes a file path as input and performs image preprocessing using TensorFlow functions. Inside the load_image function, the image is read from the file path using TensorFlow's io.read_file function, which reads the image data as a byte string. The decode_image function from TensorFlow's image module is used to decode the image from the byte string format.\n",
    "\n",
    "The image is resized to the desired dimensions (img_size) using TensorFlow's image.resize function. This ensures that all images have the same size for consistency during model training. The color space of the image is converted from the default BGR (commonly used in OpenCV) to grayscale using TensorFlow's image.rgb_to_grayscale function. This converts the image to a single-channel grayscale representation.\n",
    "\n",
    "The pixel values of the image are normalized by converting the data type to float32 and dividing by 255.0. This normalization step scales the pixel values to the range of [0, 1], which is a common practice in deep learning models. The preprocessed image is returned as the output of the load_image function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOmdQbtHduIy"
   },
   "outputs": [],
   "source": [
    "def generate_numpy_arrays(dataframe):\n",
    "    # Get the total number of samples in the input dataframe\n",
    "    num_samples = len(dataframe)\n",
    "\n",
    "    # Initialize the data array with zeros\n",
    "    data = np.zeros((num_samples, img_size[0], img_size[1], 3), dtype=np.float32)\n",
    "\n",
    "    # Convert emotion labels to one-hot-encoded labels\n",
    "    labels = to_categorical(le.transform(dataframe['emotion']), num_classes=len(le.classes_))\n",
    "\n",
    "    # Define a helper function to load and preprocess an image\n",
    "    def process_image(index):\n",
    "        row = dataframe.iloc[index]\n",
    "        image_path = os.path.join(wikiart_dir, row['art_style'], row['painting'] + '.jpg')\n",
    "        return load_image(image_path)\n",
    "\n",
    "    # Load and preprocess images in parallel\n",
    "    images = Parallel(n_jobs=-1)(delayed(process_image)(i) for i in tqdm(range(num_samples), desc='Loading Images'))\n",
    "\n",
    "    # Store the preprocessed images in the data array\n",
    "    data[:] = images\n",
    "\n",
    "    # Convert labels to float32\n",
    "    labels = labels.astype(np.float32)\n",
    "\n",
    "    # Return the data and labels arrays\n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93_yXrVe0rw5"
   },
   "source": [
    "\n",
    "The provided code defines a function called generate_numpy_arrays that processes a DataFrame containing image data and generates numpy arrays for the images and their corresponding labels. Let's understand how the code works:\n",
    "\n",
    "The function takes a DataFrame (dataframe) as input, which contains image data and emotion labels.  The total number of samples in the input DataFrame is obtained using the len function, and it is stored in the num_samples variable.\n",
    "\n",
    "An array called data is initialized with zeros. It has dimensions (num_samples, img_size[0], img_size[1], 3) and a data type of float32. This array will hold the preprocessed image data.\n",
    "\n",
    "The emotion labels in the DataFrame are transformed into one-hot-encoded labels using the to_categorical function. The labels are first transformed using the label encoder (le) to convert them into numeric representations. The number of classes is determined by the length of the label encoder's classes (len(le.classes_)).\n",
    "\n",
    "The code defines a helper function, process_image, which takes an index as input and retrieves the corresponding row from the DataFrame. It constructs the file path for the image by joining the directory path (wikiart_dir), art style, and painting name with the appropriate file extension. This function then calls the load_image function (defined earlier) to preprocess the image.\n",
    "\n",
    "The Parallel class from the joblib library is used to load and preprocess the images in parallel. The Parallel class runs multiple instances of the process_image function concurrently, speeding up the image loading process. The n_jobs=-1 parameter specifies that all available CPU cores should be used for parallel processing.\n",
    "\n",
    "The images list is populated with the preprocessed images obtained from parallel processing. The tqdm function is used to display a progress bar indicating the loading progress. The preprocessed images in the images list are stored in the data array using the slicing operation data[:] = images. This copies the elements of the images list to the corresponding positions in the data array.\n",
    "\n",
    "The data type of the labels is converted to float32 using the astype method.Finally, the function returns the data array (containing the preprocessed images) and the labels array (containing the corresponding labels) as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fv6mF8ddh1z"
   },
   "source": [
    "train_df: 72% of the data for training (0.8 * 0.9 = 0.72)\n",
    "\n",
    "val_df: 8% of the data for validation (0.8 * 0.1 = 0.08)\n",
    "\n",
    "test_df: 20% of the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j0ZT4kCxSKMD",
    "outputId": "ebb2b690-857e-4a11-a892-259ed4c52f4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 327372\n",
      "Number of validation samples: 36375\n",
      "Number of test samples: 90937 \n",
      "\n",
      "Number of reduced training samples: 16369\n",
      "Number of reduced validation samples: 3638\n",
      "Number of reduced test samples: 9094\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(artemis_data, test_size=0.2, random_state=2021)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2021)\n",
    "\n",
    "# Find Number of samples used:\n",
    "num_train_samples = len(train_df)\n",
    "num_val_samples = len(val_df)\n",
    "num_test_samples = len(test_df)\n",
    "\n",
    "print(f\"Number of training samples: {num_train_samples}\")\n",
    "print(f\"Number of validation samples: {num_val_samples}\")\n",
    "print(f\"Number of test samples: {num_test_samples} \\n\")\n",
    "\n",
    "# Reduce the datasamples to train on colab:\n",
    "\n",
    "#create reduction ratios \n",
    "train_frac = 0.05\n",
    "val_frac = 0.1\n",
    "test_frac = 0.1\n",
    "\n",
    "#Create the reduced datasets\n",
    "train_df_reduced = train_df.sample(frac=train_frac, random_state=2021)\n",
    "val_df_reduced = val_df.sample(frac=val_frac, random_state=2021)\n",
    "test_df_reduced = test_df.sample(frac=test_frac, random_state=2021)\n",
    "\n",
    "num_train_samplesr = len(train_df_reduced)\n",
    "num_val_samplesr = len(val_df_reduced)\n",
    "num_test_samplesr =len(test_df_reduced)\n",
    "\n",
    "print(f\"Number of reduced training samples: {num_train_samplesr}\")\n",
    "print(f\"Number of reduced validation samples: {num_val_samplesr}\")\n",
    "print(f\"Number of reduced test samples: {num_test_samplesr}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcrpFRZmUOMU",
    "outputId": "872d478a-ca3b-4afc-b7d5-6a9490672775"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Images:   5%|▌         | 888/16369 [02:15<20:45, 12.43it/s]/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Loading Images: 100%|██████████| 16369/16369 [23:15<00:00, 11.73it/s]\n",
      "Loading Images:  50%|████▉     | 1812/3638 [00:31<00:33, 54.68it/s]/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Loading Images: 100%|██████████| 3638/3638 [01:07<00:00, 53.71it/s]\n",
      "Loading Images:  12%|█▏        | 1080/9094 [00:19<02:24, 55.37it/s]/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Loading Images: 100%|██████████| 9094/9094 [04:52<00:00, 31.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate the NumPy arrays for each dataset\n",
    "train_data, train_labels = generate_numpy_arrays(train_df_reduced)\n",
    "val_data, val_labels = generate_numpy_arrays(val_df_reduced)\n",
    "test_data, test_labels = generate_numpy_arrays(test_df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7TCcC5sq-lH"
   },
   "outputs": [],
   "source": [
    "# Save the NumPy arrays to Google Drive\n",
    "save_dir = '/content/drive/MyDrive/DeepLearningProject/GeneratedData5p'\n",
    "\n",
    "np.save(save_dir + '/train_data.npy', train_data)\n",
    "np.save(save_dir + '/train_labels.npy', train_labels)\n",
    "\n",
    "# Save the arrays as compressed NumPy files\n",
    "np.savez_compressed(save_dir + '/train_data.npz', data=train_data)\n",
    "np.savez_compressed(save_dir + '/train_labels.npz', labels=train_labels)\n",
    "# Repeat for other arrays\n",
    "\n",
    "\n",
    "np.save(save_dir + '/val_data.npy', val_data)\n",
    "np.save(save_dir + '/val_labels.npy', val_labels)\n",
    "\n",
    "# Save the arrays as compressed NumPy files\n",
    "np.savez_compressed(save_dir + '/val_data.npz', data=train_data)\n",
    "np.savez_compressed(save_dir + '/val_labels.npz', labels=train_labels)\n",
    "\n",
    "np.save(save_dir + '/test_data.npy', test_data)\n",
    "np.save(save_dir + '/test_labels.npy', test_labels)\n",
    "\n",
    "# Save the arrays as compressed NumPy files\n",
    "np.savez_compressed(save_dir + '/test_data.npz', data=train_data)\n",
    "np.savez_compressed(save_dir + '/test_labels.npz', labels=train_labels)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f01e154e0e239481fad069e6327377acb9793762451bde69dc15e49401a33717"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
